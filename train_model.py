import pandas as pd


df = pd.read_csv("data.csv")

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score

# ğŸ¯ Target variable
y = df['Desired_Savings']

# âœ… Feature variables
X = df.drop(columns=[
    'Desired_Savings', 
    'Desired_Savings_Percentage', 
    'Potential_Savings_Groceries', 
    'Potential_Savings_Transport', 
    'Potential_Savings_Eating_Out',
    'Potential_Savings_Entertainment',
    'Potential_Savings_Utilities',
    'Potential_Savings_Healthcare',
    'Potential_Savings_Education',
    'Potential_Savings_Miscellaneous'
])

# ğŸ” Categorical columns to encode
categorical_cols = ['Occupation', 'City_Tier']

# ğŸ’¡ Use ColumnTransformer to apply OneHotEncoding only to categoricals
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)
    ],
    remainder='passthrough'  # Keep other columns as is
)

# ğŸ“¦ ML Pipeline
model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))
])

# ğŸ“Š Split dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ğŸ§  Train the model
model.fit(X_train, y_train)

# ğŸ“ˆ Predict and evaluate
y_pred = model.predict(X_test)

print("MAE:", mean_absolute_error(y_test, y_pred))
print("RÂ² Score:", r2_score(y_test, y_pred))

import joblib
joblib.dump(model, "savings_predictor.pkl")
print("âœ… Model trained and saved!")